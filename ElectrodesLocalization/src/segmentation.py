from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
import numpy as np
from numpy.linalg import norm
from utils import log
from typing import List
from sklearn.linear_model import LinearRegression

def __flip_positive_x(a: np.ndarray) -> np.ndarray:
    """In a list of vectors, flips each vector if necessary, so that its
    x-component is positive.
    
    ### Input:
    - a: an array of shape (M, N) that contains M vectors of N components each.
    
    ### Output
    - output: an array of shape (M, N) where each vector a[i] has been flipped
    (or not) such that output[i, 0] is positive. All vectors a[i] and a[j] are
    treated indepedently from each other."""
    return np.where(a[:,0:1] >= 0, a, -a)

def __get_vector_K_nearest(contacts: np.ndarray, k:int) -> List[np.ndarray]:
    """Returns the vector between each contact and its K closest neighbors.

    ### Inputs:
    - contacts: an array of shape (N, 3) that contains the coordinates of the 
    input.
    - k: the number of neighbors to include.

    ### Outputs:
    - neighbors: an array of shape (K, N, 3) that contains the absolute
    coordinates of the K closest neighbors.
    - vectors: an array of shape (K, N, 3) that contains the vectors between
    each contact and its K closest neighbors. vectors[k,i,:] contains the 
    vector towards the k-th closest neighbor of contact i.
    """
    # Computing the distance map of the contacts
    # Generated by ChatGPT
    diff = contacts[:, np.newaxis, :] - contacts[np.newaxis, :, :]
    distance_map = np.sqrt(np.sum(diff**2, axis=-1))

    # a value that makes an entry of the distance map unpickable
    UNPICKABLE = distance_map.max()    

    # Sabotaging the diagonal so that a contact cannot be closest to itself
    n = contacts.shape[0]
    distance_map[range(n), range(n)] = UNPICKABLE

    # Computing the N closest contact to each contact
    # closest[i] is the coordinates of the contact that is closest to contact i
    neighbors = []
    for i in range(k):
        closest_indices = np.argmin(distance_map, axis=1)   # Shape (N,)
        neighbors.append(contacts[closest_indices])    # Shape (N, 3)
        distance_map[range(n), closest_indices] = UNPICKABLE


    neighbors = np.stack(neighbors)
    return neighbors, (np.stack(neighbors) - contacts[np.newaxis,:])


def __get_dir_regression(contacts: np.ndarray, k: int) -> np.ndarray:
    """TODO write documentation"""
    neigh, _ = __get_vector_K_nearest(contacts, k)
    data = np.concatenate([neigh, contacts[np.newaxis,:]])
    intercepts = []
    dirs = []
    # Fitting one regression for each set of contact and neighbors
    for i in range(contacts.shape[0]):
        x = data[:,i,:1]
        y = data[:,i,1:]
        model = LinearRegression(fit_intercept=True)
        model.fit(x, y)
        intercepts.append(model.intercept_)
        dirs.append(model.coef_.ravel())
    return np.stack(intercepts), np.stack(dirs)


def __get_direction_neighbors(contacts: np.ndarray, k:int) -> np.ndarray:
    """TODO write documentation
    
    In: (N, 3)
    Out: (N, 3) but accounts for angle between closest, c and other neighbors 
    (must be < 180Â°)."""
    _, vectors = __get_vector_K_nearest(contacts, k)

    if k <= 1:
        return vectors[0]
    
    # For each contact, flipping the neighbor vectors that go in a direction
    # opposite to the first neighbor vector. This is to ensure that all vectors
    # of each contact go in the same direction, and won't cancel each other out
    # when computing their average.
    # Generated by ChatGPT
    dot_products = np.sum(vectors*vectors[0], axis=2)  # Shape (K, N)
    flip_mask = dot_products < 0  # Shape (K, N)

    # Expand dimensions to match (K, N, 3)
    flip_mask = np.expand_dims(flip_mask, axis=2).repeat(3, axis=2)
    vectors[flip_mask] = -vectors[flip_mask]
    
    return vectors.mean(axis=0)


def __feature_vector_closest(contacts: np.ndarray) -> np.ndarray:
    """Returns the vector that leads each contact to its closest contact.

    ### Input:
    - contacts: an array of shape (N, 3) that contains the coordinates of the N
    contacts.

    ### Output:
    - vector_posx: the array of shape (N, 3) that contains, for each contact, 
    the vector to its closest contact. Each vector is potentially flipped as
    to have a positive x-component."""

    # Computing the vector between each contact and its closest contact
    _, vector = __get_vector_K_nearest(contacts, k=1)[0]    # Shape (N, 3)

    # Adjusting the weight of this feature
    # and multiplying where needed to have a positive x component
    vector /= np.mean(np.linalg.norm(vector, axis=1))   # dividing by norm mean
    vector *= np.std(contacts, axis=0)
    vector_posx = __flip_positive_x(vector)

    return  vector_posx


def __feature_proj_circle(contacts):

    def __proj_circle(
            sc: np.ndarray, 
            sr: float,
            lo: np.ndarray,
            lu: np.ndarray
    ) -> np.ndarray:
        # Source: https://en.wikipedia.org/wiki/Line%E2%80%93sphere_intersection
        lu = __flip_positive_x(lu) 

        # TODO remove if unnecessary
        #lu1 = lu / norm(lu, axis=1)[:,np.newaxis]
        #delta = np.diag(lu1 @ (lo-sc).T)**2 - (norm(lo-sc, axis=1)**2 - sr**2)
        #sol = - np.diag(lu1 @ (lo-sc).T)**2 + np.sqrt(delta)

        a = norm(lu, axis=1)**2
        b = np.diag(2 * lu @ (lo-sc).T)   # only diag interests us
        c = norm(lo-sc, axis=1)**2 - sr**2

        # array of shape (N,) that corresponds to the factor of each row in lu
        sol = (-b + np.sqrt(b**2 - 4*a*c)) / (2*a)

        # Projecting line onto circle
        # Broadcasting sol to convert shape (N,) into (N, 3)
        return lo + sol[:, np.newaxis] * lu

    sc = contacts.mean(axis=0)
    sr = 3 * contacts.std(axis=0).max()
    lo = contacts
    lu = __feature_vector_closest(contacts)

    return __proj_circle(sc, sr, lo, lu)


def __feature_proj_plane_new(
        contacts: np.ndarray, 
        xval: float=0, 
        k:int=3
) -> np.ndarray:
    """This function returns features for the given list of contacts
    coordinates. For each contact:
    - its k nearest neighbors within 'contacts' are fetched;
    - a line is estimated by linear regression on these k+1 coordinates
    (the contact itself and its k neighbors);
    - the coordinates (y_p, z_p) are fetched where the line intersects with the
    plane x = xval. These coordinates (y_p, z_p) are the features returned for
    the contact.

    ### Inputs:
    - contacts: an array of shape (N, 3) that contains the coordinates of the N
    contacts.
    - xval: the position of the plane onto which to project the linear 
    regressions. Mentioned plane follows the equation x = xval.
    - k: the number of neighbors to retrieve for each contact to compute a
    linear regression.

    ### Output:
    - intersections: an array of shape (N, 2) such that 'intersections[i]'
    contains the features of 'contacts[i]', which are computed as stated above.
    """
    intercepts, coefs = __get_dir_regression(contacts, k)
    return intercepts + xval * coefs


def __feature_line_params(
        contacts: np.ndarray, 
        xval: float=0, 
        k:int=3
) -> np.ndarray:
    """TODO write documentation"""
    intercepts, coefs = __get_dir_regression(contacts, k)
    return (intercepts + xval * coefs), coefs


def __feature_proj_smart_plane(
        contacts: np.ndarray, 
        k:int=3
) -> np.ndarray:
    """TODO write documentation
    
    Ref: https://en.wikipedia.org/wiki/Line%E2%80%93plane_intersection"""
    ### Lines parameters
    # Intercepts and coefs of equations [y, z] = coefs[i] * x + intercepts[i]
    # Both of shape (N, 2)
    intercepts, coefs = __get_dir_regression(contacts, k)
    # The points and directional vectors that define the lines.
    # Such that Line[i] := {(x, y, z)[i] = p[i] + v[i]*t | t real} 
    # - Points.Shape (N, 3). Format (0, p_y[i], p_z[i])
    P = np.concatenate([np.zeros((intercepts.shape[0], 1)), intercepts], axis=1)
    # - Directional vectors. Shape (N, 3). Format (1, v_y[i], v_z[i])
    V = np.concatenate([np.ones((coefs.shape[0], 1)), coefs], axis=1)

    ### Plane parameters
    normalize = lambda u: u / np.linalg.norm(u)
    # The origin of the plane. Shape (3,)
    p0 = contacts.mean(axis=0)
    # The normal of the plane. Shape (3,) and value [1, coef_y, coef_z]
    n = np.array([1, *coefs.mean(axis=0)])
    # The two unit vectors that define the plane. Shapes (3,)
    v0 = normalize(np.array([-n[1], 1, 0]))
    v1 = normalize(np.array([1, n[1], -(1+n[1]**2)/n[2]]))
    
    ### Projecting the 3D contacts into the 2D plane and retrieving coords.
    denom = np.dot(V, np.cross(v0, v1))    # Shape (N,)
    denom = denom.reshape((denom.shape[0], 1))    # Shape (N, 1)
    a = - (P - p0) / denom    # Shape (N, 3)
    u = np.sum(np.cross(v1, -V) * a, axis=1)   # Coordinate along v0 in plane. (N,) 
    v = np.sum(np.cross(-V, v0) * a, axis=1)    # Coordinate along v1 in plane. (N,)

    return np.stack([u, v], axis=1), coefs



def __extract_features(
        contacts: np.ndarray, 
        feat_list: List[str] = ["coords"]
) -> np.ndarray:
    """From the coordinates of the contacts, extracts and returns the demanded 
    features used in the clustering technique.

    ### Inputs:
    - contacts: an array of shape (N, 3) that contains the coordinates of the N
    contacts to cluster.
    - feat_list: a list of the features to include in the output. The list of
    available feature names is given below.

    ### Output:
    - features: an array of shape (N, M) that contains the M features for each 
    of the N contacts.
    
    Available features:
    - "coords": the coordinates of c 
    - "vect_closest": the vector from c to its closest contact, potentially 
    multiplied by -1 as to have a positive x component in the vector. 
    E.g. vectors (-1, 2, 3) and (1, -2, -3) are considered the same.
    - "proj_closest: projects the line between c and its closest neighbor on a
    big circle, and returns the coordinates of the projection"""
    features = []

    if "coords" in feat_list:
        f = contacts
        features.append(f)
    if "vect_closest" in feat_list:
        f = __feature_vector_closest(contacts)
        features.append(f)
    if "proj_closest_sphere" in feat_list:
        f = __feature_proj_circle(contacts)
        features.append(f)
    if "proj_plane_new" in feat_list:
        f1 = __feature_proj_plane_new(contacts, xval=contacts[:,0].min(), k=3)
        f2 = __feature_proj_plane_new(contacts, xval=contacts[:,0].max(), k=3)
        features.append(f1)
        features.append(f2)
    if "line_params" in feat_list:
        f1, f2 = __feature_line_params(contacts, k=3)
        features.append(f1)
        features.append(f2)
    if "smart_plane" in feat_list:
        f1, f2 = __feature_proj_smart_plane(contacts, k=3)
        features.append(f1)
        features.append(f2)

    assert len(features) > 0, "At least one valid feature name must be given."
    return np.concatenate(features, axis=1)


def segment_electrodes(
        contacts: np.ndarray,
        n_electrodes: int
) -> np.ndarray:
    """Groups contacts into electrodes.
    
    ### Inputs:
    - contacts: an array of shape (N, 3) that contains the coordinates of the
    N contacts to group into electrodes.
    - n_electrodes: the number of electrodes to group the contacts.
    
    ### Output:
    - labels: an array of shape (N,) that contains the label in 
    {0, ..., n_electrodes-1} of each contact"""
    # Feature extraction
    feat_list = [
        #"coords", 
        #"vect_closest",
        #"proj_closest_sphere",
        #"proj_plane_new",
        #"line_params",
        "smart_plane"
    ]
    features = __extract_features(contacts, feat_list)

    # Applying Gaussian Mixtures to retrieve 'labels', an array of shape (N,) 
    # that contains the label of each contact (label is in range 
    # [0, n_electrodes)). The label is the id of the electrode.
    gauss_mixt = GaussianMixture(
        n_components=n_electrodes,
        covariance_type='full',
        n_init=5,
        init_params='k-means++',
        random_state=42
    )
    labels = gauss_mixt.fit_predict(features)    # Shape (N,)

    return labels



### POST PROCESSING

def __postprocess(contacts, labels, n_electrodes):
    # TODO relocate in postprocessing.py
    log("Postprocessing electrodes")
    labels = labels.copy()

    # TODO debug so that labels end up in range [0, n_electrodes)
    uniques = np.unique(labels)
    while len(uniques) > n_electrodes:
        # Regress electrode-wise
        def __get_regression(l):
            data = contacts[labels == l]    # shape (K, 3)

            x = data[:,(1,)]
            y = data[:,(0,2)]
            model = LinearRegression(fit_intercept=True)
            model.fit(x, y)

            return model.intercept_, model.coef_.ravel()
        
        inters, dirs = [], []
        for l in uniques:
            inter, dir = __get_regression(l)    # Shapes (2,) and (2,)
            inters.append(inter)
            dirs.append(dir)
        inters = np.stack(inters)    # Shape (K, 2)
        dirs   = np.stack (dirs)

        # Project onto both planes (x-max and x-min)
        proj_min = inters + contacts[1,:].min() * dirs
        proj_max = inters + contacts[1,:].max() * dirs
        projs = np.concatenate([proj_min, proj_max], axis=1)    # Shape (K, 4)

        # Distance map
        diff = projs[:, np.newaxis, :] - projs[np.newaxis, :, :]
        distance_map = np.sqrt(np.sum(diff**2, axis=-1))
        n = len(uniques)
        distance_map[range(n), range(n)] = distance_map.max()

        # Selects two closest electrodes (= projections)
        i, j = np.unravel_index(distance_map.argmin(), distance_map.shape)

        # Merge similar electrodes
        li = uniques[i]
        lj = uniques[j]
        labels[labels == lj] = li
        uniques = np.unique(labels)

    return labels
