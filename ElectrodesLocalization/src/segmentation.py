from sklearn.cluster import KMeans, DBSCAN
from sklearn.mixture import GaussianMixture
import numpy as np
from numpy.linalg import norm
from utils import log, get_regression_line_parameters
from typing import List, Tuple
from sklearn.linear_model import LinearRegression


def __flip_positive_x(a: np.ndarray) -> np.ndarray:
    """In a list of vectors, flips each vector if necessary, so that its
    x-component is positive.
    
    ### Input:
    - a: an array of shape (M, N) that contains M vectors of N components each.
    
    ### Output
    - output: an array of shape (M, N) where each vector a[i] has been flipped
    (or not) such that output[i, 0] is positive. All vectors a[i] and a[j] are
    treated indepedently from each other."""
    return np.where(a[:,0:1] >= 0, a, -a)

def __get_vector_K_nearest(contacts: np.ndarray, k:int) -> List[np.ndarray]:
    """Returns the vector between each contact and its K closest neighbors.

    ### Inputs:
    - contacts: an array of shape (N, 3) that contains the coordinates of the 
    input.
    - k: the number of neighbors to include.

    ### Outputs:
    - neighbors: an array of shape (K, N, 3) that contains the absolute
    coordinates of the K closest neighbors.
    - vectors: an array of shape (K, N, 3) that contains the vectors between
    each contact and its K closest neighbors. vectors[k,i,:] contains the 
    vector towards the k-th closest neighbor of contact i.
    """
    # Computing the distance map of the contacts
    # Generated by ChatGPT
    diff = contacts[:, np.newaxis, :] - contacts[np.newaxis, :, :]
    distance_map = np.sqrt(np.sum(diff**2, axis=-1))

    # a value that makes an entry of the distance map unpickable
    UNPICKABLE = distance_map.max()    

    # Sabotaging the diagonal so that a contact cannot be closest to itself
    n = contacts.shape[0]
    distance_map[range(n), range(n)] = UNPICKABLE

    # Computing the N closest contact to each contact
    # closest[i] is the coordinates of the contact that is closest to contact i
    neighbors = []
    for i in range(k):
        closest_indices = np.argmin(distance_map, axis=1)   # Shape (N,)
        neighbors.append(contacts[closest_indices])    # Shape (N, 3)
        distance_map[range(n), closest_indices] = UNPICKABLE


    neighbors = np.stack(neighbors)
    return neighbors, (np.stack(neighbors) - contacts[np.newaxis,:])


def __get_regression_params_on_neighbors(
        contacts: np.ndarray, k: int
    ) -> Tuple[np.ndarray]:
    """TODO write documentation"""
    neigh, _ = __get_vector_K_nearest(contacts, k)    # Shape (k, N, 3)

    # For each contact (index 1) the coordinates (index 2) 
    # of itself and its neighbors (index 1). Shape (k+1, N, 3)
    all_data = np.concatenate([neigh, contacts[np.newaxis,:]])    

    points = []
    directions = []
    # Fitting one regression for each set of contact and neighbors
    for i in range(contacts.shape[0]):
        # Points and direction vectors of regression around contact i.
        # Shapes (3,)
        p_i, v_i = get_regression_line_parameters(all_data[:,i,:])
        points.append(p_i)
        directions.append(v_i)
    
    # Shapes (N, 3)
    return np.stack(points), np.stack(directions)


def __feature_vector_closest(contacts: np.ndarray) -> np.ndarray:
    """Returns the vector that leads each contact to its closest contact.

    ### Input:
    - contacts: an array of shape (N, 3) that contains the coordinates of the N
    contacts.

    ### Output:
    - vector_posx: the array of shape (N, 3) that contains, for each contact, 
    the vector to its closest contact. Each vector is potentially flipped as
    to have a positive x-component."""

    # Computing the vector between each contact and its closest contact
    _, vector = __get_vector_K_nearest(contacts, k=1)[0]    # Shape (N, 3)

    # Adjusting the weight of this feature
    # and multiplying where needed to have a positive x component
    vector /= np.mean(np.linalg.norm(vector, axis=1))   # dividing by norm mean
    vector *= np.std(contacts, axis=0)
    vector_posx = __flip_positive_x(vector)

    return  vector_posx


def __feature_proj_sphere(contacts):

    def __proj_sphere(
            sc: np.ndarray, 
            sr: float,
            lo: np.ndarray,
            lu: np.ndarray
    ) -> np.ndarray:
        # Source: https://en.wikipedia.org/wiki/Line%E2%80%93sphere_intersection
        lu = __flip_positive_x(lu) 

        # TODO remove if unnecessary
        #lu1 = lu / norm(lu, axis=1)[:,np.newaxis]
        #delta = np.diag(lu1 @ (lo-sc).T)**2 - (norm(lo-sc, axis=1)**2 - sr**2)
        #sol = - np.diag(lu1 @ (lo-sc).T)**2 + np.sqrt(delta)

        a = norm(lu, axis=1)**2
        b = np.diag(2 * lu @ (lo-sc).T)   # only diag interests us
        c = norm(lo-sc, axis=1)**2 - sr**2

        # array of shape (N,) that corresponds to the factor of each row in lu
        sol = (-b + np.sqrt(b**2 - 4*a*c)) / (2*a)

        # Projecting line onto circle
        # Broadcasting sol to convert shape (N,) into (N, 3)
        return lo + sol[:, np.newaxis] * lu
    
    # Sphere parameters: center and radius
    sc = contacts.mean(axis=0)
    # setting radius so that sphere contains all contacts
    sr = norm(contacts-sc, axis=1).max()  

    # Lines parameters: points and directions
    lo = contacts
    lu = __feature_vector_closest(contacts)

    return __proj_sphere(sc, sr, lo, lu)


def __feature_proj_plane_new(
        contacts: np.ndarray, 
        xval: float=0, 
        k:int=3
) -> np.ndarray:
    """This function returns features for the given list of contacts
    coordinates. For each contact:
    - its k nearest neighbors within 'contacts' are fetched;
    - a line is estimated by linear regression on these k+1 coordinates
    (the contact itself and its k neighbors);
    - the coordinates (y_p, z_p) are fetched where the line intersects with the
    plane x = xval. These coordinates (y_p, z_p) are the features returned for
    the contact.

    ### Inputs:
    - contacts: an array of shape (N, 3) that contains the coordinates of the N
    contacts.
    - xval: the position of the plane onto which to project the linear 
    regressions. Mentioned plane follows the equation x = xval.
    - k: the number of neighbors to retrieve for each contact to compute a
    linear regression.

    ### Output:
    - intersections: an array of shape (N, 2) such that 'intersections[i]'
    contains the features of 'contacts[i]', which are computed as stated above.
    """
    intercepts, coefs = __get_regression_params_on_neighbors(contacts, k)
    return intercepts[:,1:] + xval * coefs[:,1:]


def __feature_line_params(
        contacts: np.ndarray, 
        xval: float=0, 
        k:int=3
) -> np.ndarray:
    """TODO write documentation"""
    intercepts, coefs = __get_regression_params_on_neighbors(contacts, k)
    return (intercepts[:,1:] + xval * coefs[:,1:]), coefs[:,1:]


def __feature_proj_smart_plane(
        contacts: np.ndarray, 
        k:int=3
) -> np.ndarray:
    """TODO write documentation
    
    Ref: https://en.wikipedia.org/wiki/Line%E2%80%93plane_intersection"""
    ### Lines parameters
    # The points and directional vectors that define the lines.
    # Such that Line[i] := {(x, y, z)[i] = p[i] + v[i]*t | t real} 
    # - Points. Shape (N, 3). Format (0, p_y[i], p_z[i])
    # - Directional vectors. Shape (N, 3). Format (1, v_y[i], v_z[i])
    P, V = __get_regression_params_on_neighbors(contacts, k)

    ### Plane parameters
    normalize = lambda u: u / np.linalg.norm(u)
    # The origin of the plane. Shape (3,)
    p0 = contacts.mean(axis=0)
    # The normal of the plane. Shape (3,) and value [1, coef_y, coef_z]
    n = V.mean(axis=0)
    # The two unit vectors that define the plane. Shapes (3,)
    v0 = normalize(np.array([-n[1], 1, 0]))
    v1 = normalize(np.array([1, n[1], -(1+n[1]**2)/n[2]]))
    
    ### Projecting the 3D contacts into the 2D plane and retrieving coords.
    denom = np.dot(V, np.cross(v0, v1))    # Shape (N,)
    denom = denom.reshape((denom.shape[0], 1))    # Shape (N, 1)
    a = - (P - p0) / denom    # Shape (N, 3)
    u = np.sum(np.cross(v1, -V) * a, axis=1)   # Coordinate along v0 in plane. (N,) 
    v = np.sum(np.cross(-V, v0) * a, axis=1)    # Coordinate along v1 in plane. (N,)

    # TODO debug remove plot plane
    global DEBUG_PLANE_CENTER, DEBUG_PLANE_NORMAL
    DEBUG_PLANE_CENTER, DEBUG_PLANE_NORMAL = p0, n

    plane_coords = np.stack([u, v], axis=1)
    angles = np.arctan(V[:,1:] / V[:,0:1])
    # Giving similar weights to both the in-plane coordinates and the angles
    return plane_coords, angles*plane_coords.std(axis=0)/angles.std(axis=0)


def __extract_features(
        contacts: np.ndarray, 
        feat_list: List[str] = ["coords"]
) -> np.ndarray:
    """From the coordinates of the contacts, extracts and returns the demanded 
    features used in the clustering technique.

    ### Inputs:
    - contacts: an array of shape (N, 3) that contains the coordinates of the N
    contacts to cluster.
    - feat_list: a list of the features to include in the output. The list of
    available feature names is given below.

    ### Output:
    - features: an array of shape (N, M) that contains the M features for each 
    of the N contacts.
    
    Available features:
    - "coords": the coordinates of c 
    - "vect_closest": the vector from c to its closest contact, potentially 
    multiplied by -1 as to have a positive x component in the vector. 
    E.g. vectors (-1, 2, 3) and (1, -2, -3) are considered the same.
    - "proj_closest: projects the line between c and its closest neighbor on a
    big circle, and returns the coordinates of the projection"""
    features = []

    if "coords" in feat_list:
        f = contacts
        features.append(f)
    if "vect_closest" in feat_list:
        f = __feature_vector_closest(contacts)
        features.append(f)
    if "proj_closest_sphere" in feat_list:
        f = __feature_proj_sphere(contacts)
        features.append(f)
    if "proj_plane_new" in feat_list:
        f1 = __feature_proj_plane_new(contacts, xval=contacts[:,0].min(), k=3)
        f2 = __feature_proj_plane_new(contacts, xval=contacts[:,0].max(), k=3)
        features.append(f1)
        features.append(f2)
    if "line_params" in feat_list:
        f1, f2 = __feature_line_params(contacts, k=3)
        features.append(f1)
        features.append(f2)
    if "smart_plane" in feat_list:
        f1, f2 = __feature_proj_smart_plane(contacts, k=3)
        features.append(f1)
        features.append(f2)

    assert len(features) > 0, "At least one valid feature name must be given."
    return np.concatenate(features, axis=1)


def segment_electrodes(
        contacts: np.ndarray,
        n_electrodes: int
) -> np.ndarray:
    """Groups contacts into electrodes.
    
    ### Inputs:
    - contacts: an array of shape (N, 3) that contains the coordinates of the
    N contacts to group into electrodes.
    - n_electrodes: the number of electrodes to group the contacts.
    
    ### Output:
    - labels: an array of shape (N,) that contains the label in 
    {0, ..., n_electrodes-1} of each contact"""
    # Feature extraction
    feat_list = [
        #"coords", 
        #"vect_closest",
        #"proj_closest_sphere",
        #"proj_plane_new",
        #"line_params",
        "smart_plane"
    ]
    features = __extract_features(contacts, feat_list)

    # Applying Gaussian Mixtures to retrieve 'labels', an array of shape (N,) 
    # that contains the label of each contact (label is in range 
    # [0, n_electrodes)). The label is the id of the electrode.
    # TODO keep or remove (mirror w/ dbscan)
    """gauss_mixt = GaussianMixture(
        n_components=n_electrodes,
        covariance_type='full',
        n_init=5,
        init_params='k-means++',
        random_state=42
    )
    labels = gauss_mixt.fit_predict(features)    # Shape (N,)"""

    # TODO move from postprocessing to utils + move import to top of file
    from postprocessing import __estimate_intercontact_distance
    dist, dist_std = __estimate_intercontact_distance(features)

    # TODO keep or remove (mirror w/ GaussianMixture)
    # TODO remove hyperparams
    dbscan = DBSCAN(eps=dist+1*dist_std, min_samples=4)
    labels = dbscan.fit_predict(features)    # Shape (N,)


    # TODO remove debug
    global FEATURES
    FEATURES = features

    return labels